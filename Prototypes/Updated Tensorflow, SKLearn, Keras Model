import glob
from imblearn.over_sampling import SMOTE
from collections import Counter
oversample = SMOTE()

path='sets'
ConcatenateAttackList = pd.concat(map(pd.read_csv, glob.glob(path + "/KaliTrained/*.csv")))
ConcatenateAttackList = pd.DataFrame(ConcatenateAttackList)
ConcatenateAttackList = ConcatenateAttackList[ConcatenateAttackList['Dst Port'] != 0]
ConcatenateAttackList = ConcatenateAttackList[ConcatenateAttackList['Src Port'] != 0]
ConcatenateAttackList = ConcatenateAttackList[ConcatenateAttackList['Dst IP'].str.contains('8.0.6.*')==False]
ConcatenateAttackList = ConcatenateAttackList.drop(['Dst IP','Timestamp','Protocol','Flow ID', 'Src Port','Src IP'],axis=1)
benign = pd.read_csv('sets/BENIGN.csv', sep=r'\s*,\s*', engine='python')
temp = [ConcatenateAttackList,benign]
ConcatenateAttackList = pd.concat(temp)
ColumnsForWindowsCIC = pd.read_csv('ColumnsForWindowsCIC.csv')
ConcatenateAttackList.columns = ColumnsForWindowsCIC.columns

pd.set_option('use_inf_as_na',True)
ConcatenateAttackList.dropna(inplace=True)

'''def deleteRedudancy(rc):
    rc = rc.drop(['Bwd PSH Flags',
                       'Bwd URG Flags',
                      'Fwd Bytes/Bulk Avg',
                      'Fwd Packet/Bulk Avg',
                       'Fwd Bulk Rate Avg',
                      'Bwd Bytes/Bulk Avg',
                      'Bwd Packet/Bulk Avg',
                      'Bwd Bulk Rate Avg'], axis=1)

    return rc

ConcatenateAttackList = deleteRedudancy(ConcatenateAttackList)
'''

#TF_GPU_HOST_MEM_LIMIT_IN_MB=5950
#physical_devices = tf.config.list_physical_devices('GPU')
try:
  tf.config.experimental.set_memory_growth(physical_devices[0], False)
except:
  # Invalid device or cannot modify virtual devices once initialized.
  pass

from keras.utils import np_utils

label_encoder = preprocessing.LabelEncoder()

y = ConcatenateAttackList['Label']
encoded_y = label_encoder.fit_transform(y)
y = np_utils.to_categorical(encoded_y)

x = ConcatenateAttackList.drop(['Label', ], axis = 1).astype(float)

sc = MinMaxScaler()
print('x_train, y_train, fitting and transforming.')
x = sc.fit_transform(x)

x,y = oversample.fit_resample(x,y)

x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.33,
                                                                            random_state=42,shuffle=True,stratify=y
                                                    )
len(x_train)
len(y_train)


X = pd.DataFrame(x_train)
print('x_train, y_train, fitted and transformed.')

with tf.device("CPU"):
    #train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(4*512).batch(512)
    validate = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(512)
    
    
model = Sequential()
print('Model initialized.')

model.add(Dense(64,input_dim=len(X.columns),activation='relu'))                     # input layer
model.add(Dense(32, activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(6, activation='softmax'))
print('Nodes added to layers.')

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='categorical_accuracy')
print('Compiled.')


callback=tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', 
                                          patience=75, min_delta=0, restore_best_weights=True, verbose=2)


print('EarlyStopping CallBack executed.')
print('Beginning fitting...')

model_hist = model.fit(x_train, y_train, epochs=1000, batch_size=512, verbose=1,
                       callbacks=[callback],validation_split=0.1)

print('Fitting completed.')               
model.save("sets/mymodel5.h5")
dump(sc, 'sets/scaler_transformTCPDCV5.joblib')
dump(label_encoder, 'sets/label_encoder40.joblib')
print('Model saved.')  


#loss history
plt.plot(model_hist.history['loss'], label="Training Loss")
plt.plot(model_hist.history['val_loss'], label="Validation Loss")
plt.legend()

#------------PREDICTION
tester = pd.read_csv('AttackTestFile.csv', sep=r'\s*,\s*', engine='python')
tester = tester[tester['Dst Port'] != 0]
tester = tester[tester['Src Port'] != 0]
tester = tester[tester['Dst IP'].str.contains('8.0.6.*')==False]
tester = tester.drop(['Dst IP','Timestamp','Protocol','Flow ID', 'Src Port','Src IP'],axis=1)
ColumnsForWindowsCIC = pd.read_csv('ColumnsForWindowsCIC.csv')
tester.columns = ColumnsForWindowsCIC.columns
#tester = deleteRedudancy(tester)

x = tester.drop(['Label', ], axis = 1)

fit_new_input = sc.transform(x)

classes_y = np.argmax(model.predict(fit_new_input), axis=-1)

predict = label_encoder.inverse_transform(classes_y)
predict
